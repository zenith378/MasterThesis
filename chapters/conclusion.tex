%!TEX root = ../dissertation.tex

\chapter{Conclusion}
\label{chp:conclusion}
%\epigraph{“In some sort of crude sense which no vulgarity, no humor, no overstatement can quite extinguish, the physicists have known sin; and this is a knowledge which they cannot lose.”}{Robert Oppenheimer}
The new software-based trigger system that LHCb introduced for the current Run~3 allowed at once to greatly reduce the data stream saved to disk an to enhance flexibility for the selection of events of physics interest. The full data stream of \SI{50}{\tera\byte\per\second} is processed with an heterogeneous computing system, leveraging the power of $\sim 500$~GPUs operating in parallel on different events.

As LHCb plans to introduce further computing power at an even earlier stage fur Run~4, a 2D cluster-finding algorithm is already operating in the current Run~3 firmware in order to determine the coordinates of all hits in the VELO. Leveraging the power of FPGA, the algorithm throughput matches the LHC collision rate of \SI{30}{\mega\hertz}.

The goal of this thesis work was to explore what further advantages might be obtained from the real-time accessibility of a flow (unprecedented in HEP) of $\sim 10^{12}$ hits/s from a precision detector, produced by the FPGA-based cluster algorithm. We decided to focus on applications that could be practically implemented with the very modest residual processing power still available within the current readout system of LHCb, and without hampering its throughput. This means basing the processing on reasonably simple statistics such as the simple counting of rates of reconstructed hits in 208 specific VELO regions. Appropriately combining them, it was shown that seven linear estimators of interest can be evaluated ``on the fly": a luminosity estimate, an average position of the luminous region in the transverse plane (x and y coordinates), as well as the average position of the two VELO halves in the two components of the transverse plane.

Regarding luminosity, it was found that each one of the implemented counters could provide a luminosity estimation and that the best way to combine them was to perform a trimmed mean on the 208 luminosity estimates. Along the various online luminosity monitoring tasks, this measurement currently represents one the best available in real-time, with 1\% precision and 0.5\% in-time stability. This measurement is currently used by the LHCb online monitoring system as an independent feedback from other luminosity counters in the experiment.

By leveraging the Principal Component Analysis, we found one way of combining the counters for luminous region and VELO position monitoring. The implemented estimators performed well both on Monte Carlo and on data, providing a measurement with a resolution in the order of $\SI{5}{\micro\meter}$ by integrating 408000 events, i.e. once every \SI{18}{\milli\second}, corresponding to a frequency $f=\SI{55}{\hertz}$. These estimators are currently displayed in the official web-page of the LHCb monitoring system, Monet, providing a reconstruction of the two VELO halves and luminous region position in real-time during data-taking periods. It is currently under investigation how this information could be integrated in the raw banks of the events, in order to use it for offline analyses and reduce systematics on VELO movements within a Run. Another option would be integrating it into the LHCb online system, accelerating the reconstruction of primary vertices and correcting the detector misalignments in real time.

These results are encouraging on two fronts: on the most specific one, we demonstrated how even a small amount of information at high statistics can be used to generate meaningful quantities for monitoring purposes at a competitive resolution and fast response. Currently, we count clusters within rectangular selection regions, each multiplied by a weight derived from PCA. These regions comprehend only 1\% of the VELO area, but exploiting the entirety of the silicon area could significantly improve the position estimators resolution.  In theory, we could narrow the selection regions down to individual pixel areas, assigning a coefficient to each pixel in the VELO detector. This process could be efficiently executed using specific Kernel functions to apply to the cluster distribution on each VELO sensor. 
%Now we are counting clusters in rectangular selection region multiplied by an appropriate weight derived with PCA. In the limit, we could restrict this area to the single pixel area and multiply each pixel in the VELO detector by an appropriate coefficient. This operation can be performed by developing appropriate Kernel functions to apply on each VELO sensor when counting all the hits on the VELO. 
The computational feasibility of this method is given by the fact that this operation can be directly performed in the FPGA during the readout of the detector, i.e. shortly after the clustering operation is executed. By leveraging all the available information in the pixel detector, the luminous region and VELO position could be given for every event, instead of once every $N$ integrated events, or at least with enhanced resolution.

On the most general front, this thesis explored the potential of a new approach to HEP data processing, by testing it on quantities that could directly be measured with the available resources. We demonstrated how the high-rate statistics produced at low level can give essential information for the event reconstruction, locally processing the large data flow of the LHCb vertex detector by using a hardware accelerator. 

The quantities estimated in this thesis (luminosity, luminous region position, and positioning of moveable detector elements) showed very good agreement with offline-reconstructed values, at a competitive resolution and with a faster response. These results demonstrated the advantages of reconstructing high-throughput computing at the very early stages of the data processing using specialised computing devices, thus encouraging a further exploitation of such technologies in the future.

%as much as the high-level reconstruction gives at low-rate, i.e. reducing the statistics to analyse.
% In a future in which pre-reconstructed data is available at a very early stage in the data acquisition chain, this approach may become widely used.

%With the upcoming Run~4 and the consequent increase in luminosity, we are preparing for a comeback of edge-computing as a primary resource to exploit.
